{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee17b24a",
   "metadata": {},
   "source": [
    "Here we are going to make the Vector Database Indexing with Chroma\n",
    "\n",
    "We are going to create the embeddings of some pokemon characteristics that are into the JSON files that we created by using the Poke API for each Pokemons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7a528",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc7fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayan\\anaconda3\\envs\\pokemon-project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda44a7",
   "metadata": {},
   "source": [
    "At the beginning, we wanted to create chroma with Gemini but we used all our credits so we changed and we used HuggingFaceEmbeddings to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ce8e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mload_dotenv\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "#Load the Gemini API key from the .env file.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder that contains JSON file for each pokemon\n",
    "POKEDEX_DIRECTORY = \"../data/pokedex\"\n",
    "#Folder that will contain the chroma embeddings \n",
    "CHROMA_DIRECTORY = \"../data/chroma_pokedex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42145040",
   "metadata": {},
   "source": [
    "Checks the existent of the chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_exists():\n",
    "    return(\n",
    "        os.path.exists(CHROMA_DIRECTORY) and os.path.isfile(os.path.join(CHROMA_DIRECTORY, \"index.sqlite3\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4e6e4",
   "metadata": {},
   "source": [
    "Function that loop through our JSON pokedex to convert the files in it into LangChain Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_documents():\n",
    "    #Builds a list of LangChain Document objects from Pokédex JSON files.\n",
    "    documents = []\n",
    "    #Loop through all JSON files of the pokedex folder\n",
    "    for filename in os.listdir(POKEDEX_DIRECTORY):\n",
    "        # Open and load each JSON file with UTF-8 encoding\n",
    "        with open(os.path.join(POKEDEX_DIRECTORY, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            # Format the Pokémon data into a structured text content string            \n",
    "            content = f\"\"\"\n",
    "            Name: {data['Name']}\n",
    "            Types: {', '.join(data['Types'])}\n",
    "\n",
    "            Description:\n",
    "            {data['Description']}\n",
    "\n",
    "            Weaknesses:\n",
    "            {', '.join(data['Weaknesses'])}\n",
    "\n",
    "            Resistances:\n",
    "            {', '.join(data['Resistances'])}\n",
    "\n",
    "            Immunities:\n",
    "            {', '.join(data['Immunities'])}\n",
    "            \"\"\".strip()\n",
    "\n",
    "            # Create a Document object with the formatted content and metadata (name and source file)\n",
    "            documents.append(Document(page_content=content, metadata={\"pokemon\": data['Name'], \"filename\": filename}))\n",
    "\n",
    "    # Return the complete list of Document objects for vector embedding\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chroma(force: bool = False):\n",
    "    # Check if the Chroma database already exists\n",
    "    if chroma_exists() and not force:\n",
    "        return\n",
    "\n",
    "    # Initialize the embedding model using HuggingFace's sentence-transformers\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    # Build the list of LangChain Document objects from Pokédex JSON files\n",
    "    documents = build_documents()\n",
    "\n",
    "    # Create and persist the Chroma vector database from the documents\n",
    "    chroma_db = Chroma.from_documents(\n",
    "        documents = documents,  # Documents containing Pokémon information\n",
    "        embedding = embeddings,  # The embedding model to use for vectorization\n",
    "        persist_directory = CHROMA_DIRECTORY,  # Directory where the database will be saved\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571e74f",
   "metadata": {},
   "source": [
    "Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7823759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayan\\AppData\\Local\\Temp\\ipykernel_7128\\1038197454.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rayan\\anaconda3\\envs\\pokemon-project\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayan\\AppData\\Local\\Temp\\ipykernel_7128\\1038197454.py:19: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_db.persist()\n"
     ]
    }
   ],
   "source": [
    "build_chroma()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokemon-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
